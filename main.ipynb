{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36875b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\Usuario\\OneDrive - epfl.ch\\Documents\\EPFL\\Basics of mobile robotics\\PROJET\\Github\\Mobile_robotics')\n",
    "import math\n",
    "import cv2 \n",
    "import time\n",
    "import importlib\n",
    "import filters \n",
    "import computer_vision\n",
    "import path_planning\n",
    "import obstacle_avoidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf19f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tdmclient.notebook.sync_var\n",
    "def set_speed(left, right):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left\n",
    "    motor_right_target = right\n",
    "    \n",
    "@tdmclient.notebook.sync_var\n",
    "def get_prox():\n",
    "    global prox_horizontal\n",
    "    obst = prox_horizontal\n",
    "    return obst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6497bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov 28 17:03:23 2021\n",
    "\n",
    "@author: henry papapatos\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "TRESH_DIST = 10 #mm\n",
    "CAMERA = 0 # Camera\n",
    "SPEED_TO_MMS = 0.3436*1.1\n",
    "YAW_TO_DEGS = 0.06086*4\n",
    "SPEED_OFFSET = 5\n",
    "FROM_KHALMAN = 0\n",
    "FROM_CAMERA = 1\n",
    "GOAL = 2\n",
    "\n",
    "\n",
    "def main():\n",
    "         \n",
    "    try:              \n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        # We need to wait a bit otherwise the image is yellow \n",
    "        time.sleep(1)\n",
    "        \n",
    "        print(\"Take the rigth image\")\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        #frame_init = cv2.cvtColor(frame_init, cv2.COLOR_BGR2RGB)\n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "            \n",
    "        # Extract vertexes, goals, thymio's start position and orientation from first frame\n",
    "        start_pos, obst_vertexes, goals_pos, px_to_mm = computer_vision.Init(frame_init)\n",
    "        \n",
    "        print(\"Px_to_mm= \", px_to_mm)\n",
    "        \n",
    "        # wtf il faut virer Ã§a\n",
    "        px_to_mm = 0.64\n",
    "        \n",
    "        computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "                \n",
    "        goal_list = path_planning.get_optimal_path(start_pos, goals_pos, obst_vertexes, \n",
    "                                                   px_to_mm, draw = True, image = frame_init)\n",
    "        \n",
    "        optimal_trajectory = goal_list.copy()\n",
    "        \n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        frame = computer_vision.get_image(cap)\n",
    "        \n",
    "        # The estimated state vector at time t-1 in the global reference frame\n",
    "        # [x_t_minus_1, y_t_minus_1, yaw_t_minus_1] \n",
    "        # [mm, mm, degrees] \n",
    "        x_est_t_minus_1, hidden_cam, mask_frame = computer_vision.vision(frame, px_to_mm)\n",
    "        \n",
    "        # The control input vector at time t-1 in the global reference frame.\n",
    "        # [v, yaw_rate]\n",
    "        # [mm/s, degrees/s] \n",
    "        u_t_minus_1 = np.array([0 ,0])\n",
    "         \n",
    "        # State covariance matrix P_t_minus_1\n",
    "        P_t_minus_1 = np.array([[1,  0,   0],\n",
    "                                [0,  1,   0],\n",
    "                                [0,  0,   1]])\n",
    "    \n",
    "        dt = 0.1 \n",
    "        v_l = 0\n",
    "        v_r = 0\n",
    "        state = 0\n",
    "        obstThrH = 1400\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        while True:\n",
    "\n",
    "            previous = time.time()\n",
    "            \n",
    "            frame = computer_vision.get_image(cap)\n",
    "            \n",
    "            # Returns the camera measurement of the robot position and a boolean \n",
    "            # indicating if the camera is hidden or not\n",
    "            obs_vector_z_t, hidden_cam, mask_frame = computer_vision.vision(frame, px_to_mm)\n",
    "            \n",
    "            computer_vision.display_obstacle(frame, start_pos, goals_pos, obst_vertexes)\n",
    "            \n",
    "            computer_vision.display_pos(frame,obs_vector_z_t, px_to_mm, hidden_cam, FROM_CAMERA)\n",
    "            \n",
    "            computer_vision.display_path(frame, optimal_trajectory, px_to_mm)\n",
    "              \n",
    "            # Run the Kalman Filter and store the \n",
    "            # optimal state and covariance estimates\n",
    "            optimal_state_estimate_t, covariance_estimate_t = filters.kf(\n",
    "                obs_vector_z_t, # Most recent sensor measurement\n",
    "                x_est_t_minus_1, # Our most recent estimate of the state\n",
    "                u_t_minus_1, # Our most recent control input\n",
    "                P_t_minus_1, # Our most recent state covariance matrix\n",
    "                dt,hidden_cam) # Indicator of the camera state\n",
    "            \n",
    "            computer_vision.display_pos(frame, optimal_state_estimate_t, px_to_mm, 0, FROM_KHALMAN)\n",
    "            computer_vision.display_pos(frame, goal_list[0], px_to_mm, 0, GOAL)\n",
    "            \n",
    "            frame = cv2.resize(frame, None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imshow('Running frame', frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            \n",
    "            mask_frame = cv2.resize(mask_frame,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imshow('mask frame', mask_frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            if np.linalg.norm(np.array([optimal_state_estimate_t[0],optimal_state_estimate_t[1]])-np.array(goal_list[0])) < TRESH_DIST:\n",
    "                goal_list.pop(0)\n",
    "                if len(goal_list) == 0:\n",
    "                    break\n",
    "                \n",
    "            # Get ready for the next timestep by updating the variable values\n",
    "            x_est_t_minus_1 = optimal_state_estimate_t\n",
    "            P_t_minus_1 = covariance_estimate_t\n",
    "            \n",
    "            # Check if obstacle in coming\n",
    "            obst = get_prox()\n",
    "            \n",
    "            # Put a name to the state instead of a number? state = \"local avoidance\" or \"global path\"\n",
    "            if state == 0:\n",
    "                for i in range(len(obst)-2):\n",
    "                # switch from goal tracking to obst avoidance if obstacle detected\n",
    "                    if (obst[i] > obstThrH):\n",
    "                        print('obst', obst)\n",
    "                        state = 1\n",
    "        \n",
    "            if state == 0:\n",
    "                # Call P controler to obtain the speed of the robot\n",
    "                v_l,v_r = filters.p_controler(optimal_state_estimate_t,goal_list[0])\n",
    "            \n",
    "            else:\n",
    "            # If we are in local avoidance state\n",
    "                v, state = obstacle_avoidance.obstacle_avoidance(obst, v_l, v_r, True)\n",
    "                v_l = v[0]\n",
    "                v_r = v[1]\n",
    "            \n",
    "            # Conversion of speed and yaw to real world values\n",
    "            v = (v_l + v_r)*SPEED_TO_MMS/2\n",
    "            yaw = (v_l-v_r)*YAW_TO_DEGS\n",
    "            u_t_minus_1 = [v, yaw]; \n",
    "            \n",
    "            # Setting the speed of the robot, correct the fact that the robot doesn't naturally go straight \n",
    "            set_speed(int(v_l), int(v_r+SPEED_OFFSET))\n",
    "\n",
    "            actual = time.time()\n",
    "            diff = actual-previous\n",
    "            if diff < dt:\n",
    "                time.sleep(dt-diff)\n",
    "            \n",
    "    finally:\n",
    "        set_speed(0, 0)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c91bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to thymio\n"
     ]
    }
   ],
   "source": [
    "print(\"connecting to thymio\")\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4022d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to camera...\n",
      "Camera connected !\n"
     ]
    }
   ],
   "source": [
    "print('Connecting to camera...')\n",
    "cap=cv2.VideoCapture(CAMERA) # Either 0 or 1, front camera or external cam\n",
    "print('Camera connected !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c50cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters...\n",
      "first parameter set\n",
      "second parameter set\n"
     ]
    }
   ],
   "source": [
    "#get the full quality of the camera\n",
    "print(\"setting parameters...\")\n",
    "cap.set(3,1920) \n",
    "print(\"first parameter set\")\n",
    "cap.set(4,1080)\n",
    "print(\"second parameter set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcce39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'obstacle_avoidance' from 'C:\\\\Users\\\\papad\\\\OneDrive\\\\Documents\\\\MA1\\\\Basic_of_mobile_robotics\\\\project\\\\Mobile_robotics\\\\obstacle_avoidance.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(filters)\n",
    "importlib.reload(path_planning)\n",
    "importlib.reload(computer_vision)\n",
    "importlib.reload(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c103c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take the rigth image\n",
      "Px_to_mm=  0.4816497514266023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1/1 [00:00<00:00, 67.58it/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab769a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c3e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "await tdmclient.notebook.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
