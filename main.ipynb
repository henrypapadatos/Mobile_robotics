{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36875b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\Usuario\\OneDrive - epfl.ch\\Documents\\EPFL\\Basics of mobile robotics\\PROJET\\Github\\Mobile_robotics')\n",
    "import math\n",
    "import cv2 \n",
    "import time\n",
    "import importlib\n",
    "import filters \n",
    "import computer_vision\n",
    "import path_planning\n",
    "import obstacle_avoidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the speed of the robot\n",
    "@tdmclient.notebook.sync_var\n",
    "def set_speed(left, right):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left\n",
    "    motor_right_target = right\n",
    "\n",
    "# Get the value of the horizontal distance sensors\n",
    "@tdmclient.notebook.sync_var\n",
    "def get_prox():\n",
    "    obst = prox_horizontal\n",
    "    return obst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6497bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESH_DIST = 10 #Distance Treshold to consider that a goal is reached\n",
    "CAMERA = 0 # Camera index\n",
    "SPEED_TO_MMS = 0.3436*1.1 #Conversion factor to convert speed to mm/s\n",
    "YAW_TO_DEGS = 0.06086*4 #Conversion factor to convert angular speed to deg/s\n",
    "SPEED_OFFSET = 5 #Speed offset to apply to the right wheel so the robot goes straight\n",
    "FROM_KHALMAN = 0 #index for plotting purpose\n",
    "FROM_CAMERA = 1 #index for plotting purpose\n",
    "GOAL = 2 #index for plotting purpose\n",
    "NO_OBSTACLE = 0 #state of the robot when no ostacles are detected\n",
    "OBSTTHRH = 1400 #Threshold to consider that an obstacle is detected\n",
    "DT = 0.1  #Period of our loop\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "         \n",
    "    try:              \n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        # We need to wait a bit otherwise the image is yellow \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Take the first image\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        # Display the image that will be analyzed\n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        cv2.waitKey(0)\n",
    "            \n",
    "        # Extract vertexes, goals, thymio's start position and orientation from first frame\n",
    "        start_pos, obst_vertexes, goals_pos, px_to_mm = computer_vision.Init(frame_init)\n",
    "        \n",
    "        computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "                \n",
    "        # Compute the optimal path and store it in goal list\n",
    "        goal_list = path_planning.get_optimal_path(start_pos, goals_pos, obst_vertexes, \n",
    "                                                   px_to_mm, draw = True, image = frame_init)\n",
    "        # Copy goal_list for plot purposes\n",
    "        optimal_trajectory = goal_list.copy()\n",
    "        \n",
    "        # Display the image with all the information on it\n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        frame = computer_vision.get_image(cap)\n",
    "        \n",
    "        # The estimated state vector at time t-1 in the global reference frame\n",
    "        # [x_t_minus_1, y_t_minus_1, yaw_t_minus_1] \n",
    "        # [mm, mm, degrees] \n",
    "        x_est_t_minus_1, hidden_cam, mask_frame = computer_vision.vision(frame, px_to_mm)\n",
    "        \n",
    "        # The control input vector at time t-1 in the global reference frame.\n",
    "        # [v, yaw_rate]\n",
    "        # [mm/s, degrees/s] \n",
    "        u_t_minus_1 = np.array([0 ,0])\n",
    "         \n",
    "        # State covariance matrix P_t_minus_1\n",
    "        P_t_minus_1 = np.array([[1,  0,   0],\n",
    "                                [0,  1,   0],\n",
    "                                [0,  0,   1]])\n",
    "        \n",
    "        v_l = 0 #Initial left wheel speed\n",
    "        v_r = 0 #Initial right wheel speed\n",
    "        state = NO_OBSTACLE #initialize the state of the robot to no obstacle detected\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        while True:\n",
    "\n",
    "            previous = time.time()\n",
    "            \n",
    "            frame = computer_vision.get_image(cap)\n",
    "            \n",
    "            # Returns the camera measurement of the robot position and a boolean \n",
    "            # indicating if the camera is hidden or not\n",
    "            obs_vector_z_t, hidden_cam, mask_frame = computer_vision.vision(frame, px_to_mm)\n",
    "            \n",
    "            computer_vision.display_obstacle(frame, start_pos, goals_pos, obst_vertexes)\n",
    "            \n",
    "            computer_vision.display_pos(frame,obs_vector_z_t, px_to_mm, hidden_cam, FROM_CAMERA)\n",
    "            \n",
    "            computer_vision.display_path(frame, optimal_trajectory, px_to_mm)\n",
    "              \n",
    "            # Run the Kalman Filter and store the \n",
    "            # optimal state and covariance estimates\n",
    "            optimal_state_estimate_t, covariance_estimate_t = filters.kf(\n",
    "                obs_vector_z_t, # Most recent sensor measurement\n",
    "                x_est_t_minus_1, # Our most recent estimate of the state\n",
    "                u_t_minus_1, # Our most recent control input\n",
    "                P_t_minus_1, # Our most recent state covariance matrix\n",
    "                DT,hidden_cam) # Indicator of the camera state\n",
    "            \n",
    "            computer_vision.display_pos(frame, optimal_state_estimate_t, px_to_mm, 0, FROM_KHALMAN)\n",
    "            computer_vision.display_pos(frame, goal_list[0], px_to_mm, 0, GOAL)\n",
    "            \n",
    "            # Display frame with all informations on it\n",
    "            frame = cv2.resize(frame, None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            \n",
    "            # Display the mask used to detect the position of the robot using opencv\n",
    "            mask_frame = cv2.resize(mask_frame,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imshow('mask frame', mask_frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            \n",
    "            # Compute the distance between the robot and its goal. If this distance < TRESH_DIST, we remove the current goal frome goal_list\n",
    "            if np.linalg.norm(np.array([optimal_state_estimate_t[0],optimal_state_estimate_t[1]])-np.array(goal_list[0])) < TRESH_DIST:\n",
    "                goal_list.pop(0)\n",
    "                # If goal list is empty, it means that the robot has completed the path, we leave the while loop\n",
    "                if len(goal_list) == 0:\n",
    "                    break\n",
    "                \n",
    "            # Get ready for the next timestep by updating the variable values\n",
    "            x_est_t_minus_1 = optimal_state_estimate_t\n",
    "            P_t_minus_1 = covariance_estimate_t\n",
    "            \n",
    "            # Check if obstacle in coming\n",
    "            obst = get_prox()\n",
    "            if state == NO_OBSTACLE:\n",
    "                for i in range(len(obst)-2):\n",
    "                # switch from goal tracking to obst avoidance if obstacle detected\n",
    "                    if (obst[i] > OBSTTHRH):\n",
    "                        state = 1\n",
    "        \n",
    "            if state == NO_OBSTACLE:\n",
    "                # Call P controler to obtain the speed of the robot\n",
    "                v_l,v_r = filters.p_controler(optimal_state_estimate_t,goal_list[0])\n",
    "            \n",
    "            else:\n",
    "                # If we are in local avoidance state\n",
    "                v, state = obstacle_avoidance.obstacle_avoidance(obst, v_l, v_r)\n",
    "                v_l = v[0]\n",
    "                v_r = v[1]\n",
    "            \n",
    "            # Conversion of speed and yaw to real world values\n",
    "            v = (v_l + v_r)*SPEED_TO_MMS/2\n",
    "            yaw = (v_l-v_r)*YAW_TO_DEGS\n",
    "            u_t_minus_1 = [v, yaw]; \n",
    "            \n",
    "            # Setting the speed of the robot, correct the fact that the robot doesn't naturally go straight \n",
    "            set_speed(int(v_l), int(v_r+SPEED_OFFSET))\n",
    "\n",
    "            # Sleep the rigth amount of time so the loop runs at a period of DT\n",
    "            actual = time.time()\n",
    "            diff = actual-previous\n",
    "            if diff < DT:\n",
    "                time.sleep(DT-diff)\n",
    "            \n",
    "    finally:\n",
    "        # Set the speed of the robot to 0 at the end\n",
    "        set_speed(0, 0)\n",
    "        # Destroy the frame when we hit a key\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c91bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"connecting to thymio\")\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4022d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Connecting to camera...')\n",
    "cap=cv2.VideoCapture(CAMERA) # Either 0 or 1, front camera or external cam\n",
    "print('Camera connected !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the full quality of the camera\n",
    "print(\"setting parameters...\")\n",
    "cap.set(3,1920) \n",
    "print(\"first parameter set\")\n",
    "cap.set(4,1080)\n",
    "print(\"second parameter set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we use the latest version of our libraries\n",
    "importlib.reload(filters)\n",
    "importlib.reload(path_planning)\n",
    "importlib.reload(computer_vision)\n",
    "importlib.reload(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c103c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab769a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "await tdmclient.notebook.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
