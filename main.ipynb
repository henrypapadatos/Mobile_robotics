{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6497bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov 28 17:03:23 2021\n",
    "\n",
    "@author: henry papapatos\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\Usuario\\OneDrive - epfl.ch\\Documents\\EPFL\\Basics of mobile robotics\\PROJET\\Github\\Mobile_robotics')\n",
    "import math\n",
    "import cv2 \n",
    "import time\n",
    "import importlib\n",
    "import filters \n",
    "import computer_vision\n",
    "import path_planning\n",
    "\n",
    "TRESH_DIST = 3 #mm\n",
    "CAMERA = 0 # Camera\n",
    "\n",
    "def main():\n",
    "         \n",
    "    try:              \n",
    "        \n",
    "        print(\"camera connected\")\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        # we need to wait a bit otherwise the image is yellow \n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(\"take the rigth image\")\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        #frame_init = cv2.cvtColor(frame_init, cv2.COLOR_BGR2RGB)\n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        cv2.imwrite(r'C:\\Users\\papad\\OneDrive\\Images\\Pellicule\\img.jpg', frame_init) #POUR TUNING PAR ELIOTT\n",
    "        \n",
    "        # Extract vertexes, goals, thymio's start position and orientation from first frame\n",
    "        start_pos, obst_vertexes, goals_pos, px_to_mm = computer_vision.Init(frame_init)\n",
    "        print(\"start pos: \", start_pos)\n",
    "        \n",
    "        computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "        \n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        cv2.imwrite(r'C:\\Users\\papad\\OneDrive\\Images\\Pellicule\\img_obstacle.jpg', frame_init) #POUR TUNING PAR ELIOTT\n",
    "        \n",
    "        goal_list = path_planning.get_optimal_path(start_pos, goals_pos, obst_vertexes, \n",
    "                                                   px_to_mm, draw = True, image = frame_init)\n",
    "        \n",
    "        cv2.imshow('frame', frame_init)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # The estimated state vector at time t-1 in the global reference frame.\n",
    "        # [x_t_minus_1, y_t_minus_1, yaw_t_minus_1]\n",
    "        x_est_t_minus_1, hidden_cam = computer_vision.vision(frame_init, px_to_mm)\n",
    "        # x_est_t_minus_1 = np.array([0.0,0.0,0.0])\n",
    "        \n",
    "        # The control input vector at time t-1 in the global reference frame.\n",
    "        # [v, yaw_rate]\n",
    "        u_t_minus_1 = np.array([0 ,0])\n",
    "         \n",
    "        # State covariance matrix P_t_minus_1\n",
    "        P_t_minus_1 = np.array([[0.1,  0,   0],\n",
    "                                [  0,0.1,   0],\n",
    "                                [  0,  0, 0.1]])\n",
    "    \n",
    "    \n",
    "        #update le dt car sinon kalman marche pas\n",
    "        dt = 1 #A voir a modifier, Aitana\n",
    "        verbose = True\n",
    "        \n",
    "        while len(goal_list)!=0:\n",
    "            \n",
    "            frame = computer_vision.get_image(cap)\n",
    "            \n",
    "            ##### APPELER get_vision_position##########\n",
    "            obs_vector_z_t, hidden_cam = computer_vision.vision(frame, px_to_mm)\n",
    "            \n",
    "            \n",
    "            computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "            \n",
    "            computer_vision.display_pos(frame, obs_vector_z_t[0:1], is_from_camera = True)\n",
    "            \n",
    "            \n",
    "            print(f'Timestep measurement={obs_vector_z_t}')\n",
    "    \n",
    "            # Run the Extended Kalman Filter and store the \n",
    "            # near-optimal state and covariance estimates\n",
    "            optimal_state_estimate_t, covariance_estimate_t = filters.ekf(\n",
    "                obs_vector_z_t, # Most recent sensor measurement\n",
    "                x_est_t_minus_1, # Our most recent estimate of the state\n",
    "                u_t_minus_1, # Our most recent control input\n",
    "                P_t_minus_1, # Our most recent state covariance matrix\n",
    "                dt,hidden_cam,verbose) # Time interval\n",
    "            \n",
    "            computer_vision.display_pos(frame, optimal_state_estimate_t[0:1], is_from_camera = False)\n",
    "            \n",
    "            cv2.imshow('running frame', frame)\n",
    "            \n",
    "            if np.linalg.norm(optimal_state_estimate_t-goal_list[0]) < TRESH_DIST:\n",
    "                goal_list.pop(0)\n",
    "                \n",
    "            # Get ready for the next timestep by updating the variable values\n",
    "            x_est_t_minus_1 = optimal_state_estimate_t\n",
    "            P_t_minus_1 = covariance_estimate_t\n",
    "            \n",
    "            #check if obstacle in coming\n",
    "            \n",
    "            #if no\n",
    "            ######APPELER PID##########\n",
    "            u_t_minus_1 = 0; # delta_v returned by PID\n",
    "            \n",
    "            #if yes, obstacle avoidance \n",
    "            \n",
    "    finally: \n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4022d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(CAMERA) # Either 0 or 1, front camera or external cam\n",
    "        \n",
    "#get the full quality of the camera\n",
    "cap.set(3,1920) \n",
    "cap.set(4,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcce39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'computer_vision' from 'C:\\\\Users\\\\papad\\\\OneDrive\\\\Documents\\\\MA1\\\\Basic_of_mobile_robotics\\\\project\\\\Mobile_robotics\\\\computer_vision.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(filters)\n",
    "importlib.reload(path_planning)\n",
    "importlib.reload(computer_vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265c103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera connected\n",
      "take the rigth image\n",
      "test2\n",
      "start pos:  (270, 73)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'insert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18224/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18224/836467040.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\papad\\OneDrive\\Images\\Pellicule\\img_obstacle.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_init\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#POUR TUNING PAR ELIOTT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         goal_list = path_planning.get_optimal_path(start_pos, goals_pos, obst_vertexes, \n\u001b[0m\u001b[0;32m     58\u001b[0m                                                    px_to_mm, draw = True, image = frame_init)\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\MA1\\Basic_of_mobile_robotics\\project\\Mobile_robotics\\path_planning.py\u001b[0m in \u001b[0;36mget_optimal_path\u001b[1;34m(start, goal, obstacle, conversion_factor, draw, image)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_optimal_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconversion_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mdist_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAstar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0moptimal_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\MA1\\Basic_of_mobile_robotics\\project\\Mobile_robotics\\path_planning.py\u001b[0m in \u001b[0;36mAstar\u001b[1;34m(start, goal, obstacle, draw, image)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mdist_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mpath_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'insert'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab769a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
