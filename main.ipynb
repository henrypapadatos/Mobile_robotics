{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f48ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov 28 17:03:23 2021\n",
    "\n",
    "@author: henry papapatos\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\Usuario\\OneDrive - epfl.ch\\Documents\\EPFL\\Basics of mobile robotics\\PROJET\\Github\\Mobile_robotics')\n",
    "import math\n",
    "import cv2 \n",
    "import time\n",
    "import filters \n",
    "import computer_vision\n",
    "import path_planning\n",
    "\n",
    "TRESH_DIST = 3 #mm\n",
    "CAMERA = 0 # Camera\n",
    "\n",
    "def main():\n",
    "         \n",
    "    try:              \n",
    "        \n",
    "        print(\"camera connected\")\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        # we need to wait a bit otherwise the image is yellow \n",
    "        time.sleep(3)\n",
    "        \n",
    "        print(\"take the rigth image\")\n",
    "        frame_init = computer_vision.get_image(cap)\n",
    "        \n",
    "        #frame_init = cv2.cvtColor(frame_init, cv2.COLOR_BGR2RGB)\n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        cv2.imwrite(r'C:\\Users\\papad\\OneDrive\\Images\\Pellicule\\img.jpg', frame_init) #POUR TUNING PAR ELIOTT\n",
    "        \n",
    "        # Extract vertexes, goals, thymio's start position and orientation from first frame\n",
    "        start_pos, obst_vertexes, goals_pos, px_to_mm = computer_vision.Init(frame_init)\n",
    "        print(\"start pos: \", start_pos)\n",
    "        \n",
    "        computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "        \n",
    "        frame_init_crop = cv2.resize(frame_init,None, fx=0.5, fy= 0.5, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        cv2.imshow('frame', frame_init_crop)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        cv2.imwrite(r'C:\\Users\\papad\\OneDrive\\Images\\Pellicule\\img_obstacle.jpg', frame_init) #POUR TUNING PAR ELIOTT\n",
    "        \n",
    "        goal_list = path_planning.get_optimal_path(start_pos, goals_pos, obst_vertexes, \n",
    "                                                   px_to_mm, draw = True, image = frame_init)\n",
    "        \n",
    "        cv2.imshow('frame', frame_init)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # The estimated state vector at time t-1 in the global reference frame.\n",
    "        # [x_t_minus_1, y_t_minus_1, yaw_t_minus_1]\n",
    "        x_est_t_minus_1, hidden_cam = computer_vision.vision(frame_init, px_to_mm)\n",
    "        # x_est_t_minus_1 = np.array([0.0,0.0,0.0])\n",
    "        \n",
    "        # The control input vector at time t-1 in the global reference frame.\n",
    "        # [v, yaw_rate]\n",
    "        u_t_minus_1 = np.array([0 ,0])\n",
    "         \n",
    "        # State covariance matrix P_t_minus_1\n",
    "        P_t_minus_1 = np.array([[0.1,  0,   0],\n",
    "                                [  0,0.1,   0],\n",
    "                                [  0,  0, 0.1]])\n",
    "    \n",
    "    \n",
    "        #update le dt car sinon kalman marche pas\n",
    "        dt = 1 #A voir a modifier, Aitana\n",
    "        verbose = True\n",
    "        \n",
    "        while len(goal_list)!=0:\n",
    "            \n",
    "            frame = computer_vision.get_image(cap)\n",
    "            \n",
    "            ##### APPELER get_vision_position##########\n",
    "            obs_vector_z_t, hidden_cam = computer_vision.vision(frame, px_to_mm)\n",
    "            \n",
    "            \n",
    "            computer_vision.display_obstacle(frame_init, start_pos, goals_pos, obst_vertexes)\n",
    "            \n",
    "            computer_vision.display_pos(frame, obs_vector_z_t[0:1], is_from_camera = True)\n",
    "            \n",
    "            \n",
    "            print(f'Timestep measurement={obs_vector_z_t}')\n",
    "    \n",
    "            # Run the Extended Kalman Filter and store the \n",
    "            # near-optimal state and covariance estimates\n",
    "            optimal_state_estimate_t, covariance_estimate_t = filters.ekf(\n",
    "                obs_vector_z_t, # Most recent sensor measurement\n",
    "                x_est_t_minus_1, # Our most recent estimate of the state\n",
    "                u_t_minus_1, # Our most recent control input\n",
    "                P_t_minus_1, # Our most recent state covariance matrix\n",
    "                dt,hidden_cam,verbose) # Time interval\n",
    "            \n",
    "            computer_vision.display_pos(frame, optimal_state_estimate_t[0:1], is_from_camera = False)\n",
    "            \n",
    "            cv2.imshow('running frame', frame)\n",
    "            \n",
    "            if np.linalg.norm(optimal_state_estimate_t-goal_list[0]) < TRESH_DIST:\n",
    "                goal_list.pop(0)\n",
    "                \n",
    "            # Get ready for the next timestep by updating the variable values\n",
    "            x_est_t_minus_1 = optimal_state_estimate_t\n",
    "            P_t_minus_1 = covariance_estimate_t\n",
    "            \n",
    "            #check if obstacle in coming\n",
    "            \n",
    "            #if no\n",
    "            ######APPELER PID##########\n",
    "            u_t_minus_1 = 0; # delta_v returned by PID\n",
    "            \n",
    "            #if yes, obstacle avoidance \n",
    "            \n",
    "    finally: \n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80764e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(CAMERA) # Either 0 or 1, front camera or external cam\n",
    "        \n",
    "#get the full quality of the camera\n",
    "cap.set(3,1920) \n",
    "cap.set(4,1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa3758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera connected\n",
      "take the rigth image\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Expected sequence length 2, got 0\n>  - Can't parse 'center'. Expected sequence length 2, got 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17908/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17908/1039373114.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mstart_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobst_vertexes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoals_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpx_to_mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputer_vision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mcomputer_vision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_obstacle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoals_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobst_vertexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mframe_init_crop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\MA1\\Basic_of_mobile_robotics\\project\\Mobile_robotics\\computer_vision.py\u001b[0m in \u001b[0;36mdisplay_obstacle\u001b[1;34m(image, start, goal, obstacle)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_obstacle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobstacle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcurrent_goal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgoal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_goal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Expected sequence length 2, got 0\n>  - Can't parse 'center'. Expected sequence length 2, got 0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2884b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
